---
id: low-latency-sessions
title: Validating sessions with low-latency
---
import CodeBlock from '@theme/CodeBlock'

Ory Cloud is an external dependency, and latency to validate a session may vary. Here's the example

```bash
curl -o /dev/null\
     -w %{time_connect}:%{time_starttransfer}:%{time_total} \
     -s https://playground.projects.oryapis.com/sessions/whoami
     -H 'ory_session_playground=MTY1MjcyMjk5OXxBenA5MVdvaXpPZ242QlZtOVNCZ2JuRWt4NVB4WFFIVGdLcmFIZl9BN0VTOHZ3VHlJbVdVenpaZl96VWtWS1p4clI3bFRkYnFBeDZwdFZGU3RvSmxyY0JpUGJLNGQwLUlfWnNCMlFlMS1CbDlBdEtjX0xoLWxmSUNmWUJWU24xWTBoNlBGM0laSHc9PXyOu8_5YP6pFxhuNLWD3fmzxdo8JWo27iy0NkF2HQ7fcA=='

0.030575:0.265693:0.265756
```

That basic example above shows:

1. 0.275457 seconds spent connecting to the playground.
1. 0.778495 seconds passed to start transferring data.
1. 0.778623 total seconds spent on the request.


## How to validate session and when do they invalidate

You can validate a session using the following options:

1. By using `toSession` method of Ory SDK
1. By calling `/sessions/whoami` endpoint

A session invalidates in these cases:

1. When the user logs out;
1. When it expires;
1. When one wants to force a user to logout by calling [revokeSession](https://github.com/ory/kratos-client-go/blob/master/docs/V0alpha2Api.md#RevokeSession).

## How to cache sessions

Caching allows reusing previously retrieved or computed data efficiently. A cache is a high-speed data storage
layer that stores a subset of data, typically transient. Future requests for that data are served up faster than
is possible by accessing the dataâ€™s primary storage location.

One of the most used strategies is to use the least recently used (LRU) cache. There are many options to use in a system:

1. Embedded in-memory caches such as LevelDB, BerkeleyDB, Flashdb, etc.
1. Using Key-Value storage such as Redis, Memcached, Aerospike cache, etc.

Depending on requirements, one can choose any of the key-value storage available but consider this:

1. Using embedded in-memory solutions can give one low latency. However, an application stores state can prevent horizontally scaling it.
1. Key-value storages add network latency, but an application does not store any state so that one can scale it without any issues.

:::warning
Be careful with the TTL for cached sessions, and do not forget to remove the session once it expires or a user logs out. Users can still have access because of cached data, leading to a potential security breach.
:::

Let us take a look at following examples. We have session middleware that validates sessions and caches data. The logic is simple

1. Try to get cached session from Redis;
1. If a session is valid, return it and do not request Ory Cloud;
1. If data does not persist, validate a session against Ory Cloud and cache it.

## Using embedded cache storage

This example uses [dgraph-io/ristretto](https://github.com/dgraph-io/ristretto) memory-bound
Go cache.

```mdx-code-block title="main.go"
import embedded from '!!raw-loader!../../../code-examples/low-latency-sessions/embedded/main.go'

<CodeBlock language="go">{embedded}</CodeBlock>
```

## Using Redis cache

The example below shows how to cache sessions using [Redis](https://redis.io)

```mdx-code-block title="main.go"
import index from '!!raw-loader!../../../code-examples/low-latency-sessions/main.go'

<CodeBlock language="go">{index}</CodeBlock>
```
The strategy above works for most cases when one has a high-throughput system.

:::warning
Caching can worsen the situation in the low-throughput systems because of [RTT](https://en.wikipedia.org/wiki/Round-trip_delay)
to the caching backend when cached data has expired.
:::

A performance difference

```
# Without caching the response time is 1.5s
[GIN] 2022/05/17 - 18:27:58 | 200 |  1.501481333s |             ::1 | GET      "/ping"

# With caching enabled the response time is 5 ms
[GIN] 2022/05/17 - 18:28:42 | 200 |    5.309667ms |             ::1 | GET      "/ping"
```

